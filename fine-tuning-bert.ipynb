{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:29:55.667587Z","iopub.status.busy":"2024-04-14T09:29:55.667179Z","iopub.status.idle":"2024-04-14T09:29:55.676383Z","shell.execute_reply":"2024-04-14T09:29:55.675305Z","shell.execute_reply.started":"2024-04-14T09:29:55.667559Z"},"trusted":true},"outputs":[],"source":["import csv\n","\n","# Define the path to your CSV file\n","csv_file_path = \"/kaggle/input/medqa-senior/dataset.csv\"\n","\n","# Define the columns you want to read\n","columns_to_read = [\"question\", \"answer\"]\n","\n","# Initialize lists to store data from each column\n","data = {col: [] for col in columns_to_read}\n","\n","# Open the CSV file and read the specified columns\n","with open(csv_file_path, \"r\", newline=\"\") as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        for col in columns_to_read:\n","            data[col].append(row[col])\n","for i in data[\"answer\"]:\n","    print(len(i))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:31:57.656468Z","iopub.status.busy":"2024-04-14T09:31:57.655397Z","iopub.status.idle":"2024-04-14T09:32:13.534791Z","shell.execute_reply":"2024-04-14T09:32:13.533650Z","shell.execute_reply.started":"2024-04-14T09:31:57.656419Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import BertForQuestionAnswering, BertTokenizer\n","from transformers import AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Define your closed-book QA dataset class\n","class ClosedBookQADataset(Dataset):\n","    def __init__(self, questions, contexts, start_positions, end_positions):\n","        self.questions = questions\n","        self.contexts = contexts\n","        self.start_positions = start_positions\n","        self.end_positions = end_positions\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"question\": self.questions[idx],\n","            \"context\": self.contexts[idx],\n","            \"start_positions\": self.start_positions[idx],\n","            \"end_positions\": self.end_positions[idx]\n","        }\n","\n","# Define your model and tokenizer\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForQuestionAnswering.from_pretrained(model_name)\n","\n","# Prepare your dataset (replace this with your actual dataset)\n","questions = data[\"question\"]\n","contexts = data[\"answer\"]\n","start_positions = [0 for i in range(14)]  # Index of the start token of the answer within the context\n","end_positions = [129, 103, 113, 150, 100, 151, 188, 99, 154, 140, 203, 155, 166, 162]    # Index of the end token of the answer within the context\n","dataset = ClosedBookQADataset(questions, contexts, start_positions, end_positions)\n","\n","# Define training parameters\n","epochs = 3\n","batch_size = 2\n","learning_rate = 5e-5\n","\n","# Prepare DataLoader\n","train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Define optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_loader:\n","        inputs = tokenizer(batch[\"question\"], batch[\"context\"], return_tensors=\"pt\", padding=True, truncation=True)\n","        start_positions = batch[\"start_positions\"]\n","        end_positions = batch[\"end_positions\"]\n","\n","        # Forward pass\n","        outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n","\n","        # Compute loss\n","        loss = outputs.loss\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}: Average Loss: {total_loss / len(train_loader)}\")\n","\n","# Save the trained model\n","tokenizer.save_pretrained(\"./model\")\n","model.save_pretrained(\"./model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:32:58.227397Z","iopub.status.busy":"2024-04-14T09:32:58.226987Z","iopub.status.idle":"2024-04-14T09:32:58.630079Z","shell.execute_reply":"2024-04-14T09:32:58.628750Z","shell.execute_reply.started":"2024-04-14T09:32:58.227366Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import BertForQuestionAnswering, BertTokenizer\n","\n","# Load the trained model\n","model_path = \"/kaggle/working/model\"\n","model = BertForQuestionAnswering.from_pretrained(model_path)\n","tokenizer = BertTokenizer.from_pretrained(model_path)\n","\n","# Define a function to perform inference\n","def predict_answer(question):\n","    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    start_scores = outputs.start_logits\n","    end_scores = outputs.end_logits\n","    start_idx = torch.argmax(start_scores)\n","    end_idx = torch.argmax(end_scores)\n","    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_idx:end_idx+1]))\n","    return answer\n","\n","# Example usage\n","question = \"What is Alzheimer's disease?\"\n","answer = predict_answer(question)\n","print(\"Answer:\", answer)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4670170,"sourceId":8113172,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
