{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8113172,"sourceType":"datasetVersion","datasetId":4670170}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import csv\n\n# Define the path to your CSV file\ncsv_file_path = \"/kaggle/input/medqa-senior/dataset.csv\"\n\n# Define the columns you want to read\ncolumns_to_read = [\"question\", \"answer\"]\n\n# Initialize lists to store data from each column\ndata = {col: [] for col in columns_to_read}\n\n# Open the CSV file and read the specified columns\nwith open(csv_file_path, \"r\", newline=\"\") as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n        for col in columns_to_read:\n            data[col].append(row[col])\nfor i in data[\"answer\"]:\n    print(len(i))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:29:55.667179Z","iopub.execute_input":"2024-04-14T09:29:55.667587Z","iopub.status.idle":"2024-04-14T09:29:55.676383Z","shell.execute_reply.started":"2024-04-14T09:29:55.667559Z","shell.execute_reply":"2024-04-14T09:29:55.675305Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"129\n103\n113\n150\n100\n151\n188\n99\n154\n140\n203\n155\n166\n162\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BertForQuestionAnswering, BertTokenizer\nfrom transformers import AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\n# Define your closed-book QA dataset class\nclass ClosedBookQADataset(Dataset):\n    def __init__(self, questions, contexts, start_positions, end_positions):\n        self.questions = questions\n        self.contexts = contexts\n        self.start_positions = start_positions\n        self.end_positions = end_positions\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        return {\n            \"question\": self.questions[idx],\n            \"context\": self.contexts[idx],\n            \"start_positions\": self.start_positions[idx],\n            \"end_positions\": self.end_positions[idx]\n        }\n\n# Define your model and tokenizer\nmodel_name = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForQuestionAnswering.from_pretrained(model_name)\n\n# Prepare your dataset (replace this with your actual dataset)\nquestions = data[\"question\"]\ncontexts = data[\"answer\"]\nstart_positions = [0 for i in range(14)]  # Index of the start token of the answer within the context\nend_positions = [129, 103, 113, 150, 100, 151, 188, 99, 154, 140, 203, 155, 166, 162]    # Index of the end token of the answer within the context\ndataset = ClosedBookQADataset(questions, contexts, start_positions, end_positions)\n\n# Define training parameters\nepochs = 3\nbatch_size = 2\nlearning_rate = 5e-5\n\n# Prepare DataLoader\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Define optimizer and loss function\noptimizer = AdamW(model.parameters(), lr=learning_rate)\n\n# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        inputs = tokenizer(batch[\"question\"], batch[\"context\"], return_tensors=\"pt\", padding=True, truncation=True)\n        start_positions = batch[\"start_positions\"]\n        end_positions = batch[\"end_positions\"]\n\n        # Forward pass\n        outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n\n        # Compute loss\n        loss = outputs.loss\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1}: Average Loss: {total_loss / len(train_loader)}\")\n\n# Save the trained model\ntokenizer.save_pretrained(\"./model\")\nmodel.save_pretrained(\"./model\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:31:57.655397Z","iopub.execute_input":"2024-04-14T09:31:57.656468Z","iopub.status.idle":"2024-04-14T09:32:13.534791Z","shell.execute_reply.started":"2024-04-14T09:31:57.656419Z","shell.execute_reply":"2024-04-14T09:32:13.533650Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Average Loss: nan\nEpoch 2: Average Loss: nan\nEpoch 3: Average Loss: nan\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BertForQuestionAnswering, BertTokenizer\n\n# Load the trained model\nmodel_path = \"/kaggle/working/model\"\nmodel = BertForQuestionAnswering.from_pretrained(model_path)\ntokenizer = BertTokenizer.from_pretrained(model_path)\n\n# Define a function to perform inference\ndef predict_answer(question):\n    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    start_scores = outputs.start_logits\n    end_scores = outputs.end_logits\n    start_idx = torch.argmax(start_scores)\n    end_idx = torch.argmax(end_scores)\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_idx:end_idx+1]))\n    return answer\n\n# Example usage\nquestion = \"What is Alzheimer's disease?\"\nanswer = predict_answer(question)\nprint(\"Answer:\", answer)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:32:58.226987Z","iopub.execute_input":"2024-04-14T09:32:58.227397Z","iopub.status.idle":"2024-04-14T09:32:58.630079Z","shell.execute_reply.started":"2024-04-14T09:32:58.227366Z","shell.execute_reply":"2024-04-14T09:32:58.628750Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Answer: [CLS] what is alzheimer ' s disease\n","output_type":"stream"}]}]}