{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:42:33.426046Z","iopub.status.busy":"2024-04-14T09:42:33.425734Z","iopub.status.idle":"2024-04-14T09:42:33.433740Z","shell.execute_reply":"2024-04-14T09:42:33.432839Z","shell.execute_reply.started":"2024-04-14T09:42:33.426020Z"},"trusted":true},"outputs":[],"source":["import csv\n","\n","# Define the path to your CSV file\n","csv_file_path = \"/kaggle/input/medqa-senior/dataset.csv\"\n","\n","# Define the columns you want to read\n","columns_to_read = [\"question\", \"answer\"]\n","\n","# Initialize lists to store data from each column\n","data = {col: [] for col in columns_to_read}\n","\n","# Open the CSV file and read the specified columns\n","with open(csv_file_path, \"r\", newline=\"\") as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        for col in columns_to_read:\n","            data[col].append(row[col])\n","for i in data[\"answer\"]:\n","    print(len(i))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:49:39.200657Z","iopub.status.busy":"2024-04-14T09:49:39.200248Z","iopub.status.idle":"2024-04-14T09:49:48.634335Z","shell.execute_reply":"2024-04-14T09:49:48.633274Z","shell.execute_reply.started":"2024-04-14T09:49:39.200619Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1: Average Loss: 5.583241939544678\n","Epoch 2: Average Loss: 3.6626630425453186\n","Epoch 3: Average Loss: 2.972608119249344\n"]},{"data":{"text/plain":["('./model/tokenizer_config.json',\n"," './model/special_tokens_map.json',\n"," './model/spiece.model',\n"," './model/added_tokens.json')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define your closed-book QA dataset class\n","class ClosedBookQADataset(Dataset):\n","    def __init__(self, questions, answers):\n","        self.questions = questions\n","        self.answers = answers\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        return {\"question\": self.questions[idx], \"answer\": self.answers[idx]}\n","\n","# Define your model and tokenizer\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","\n","# Prepare your dataset (replace this with your actual dataset)\n","questions = data[\"question\"]  # List of questions\n","answers = data[\"answer\"]    # List of corresponding answers\n","dataset = ClosedBookQADataset(questions, answers)\n","\n","# Define training parameters\n","epochs = 3\n","batch_size = 4\n","learning_rate = 3e-4\n","\n","# Prepare DataLoader\n","train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Define optimizer and loss function\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_loader:\n","        inputs = tokenizer(batch[\"question\"], return_tensors=\"pt\", padding=True, truncation=True)\n","        labels = tokenizer(batch[\"answer\"], return_tensors=\"pt\", padding=True, truncation=True)\n","\n","        # Forward pass\n","        outputs = model(**inputs, labels=labels[\"input_ids\"])\n","\n","        # Compute loss\n","        loss = outputs.loss\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}: Average Loss: {total_loss / len(train_loader)}\")\n","\n","# Save the trained model\n","model.save_pretrained(\"./model\")\n","tokenizer.save_pretrained(\"./model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T09:50:16.588121Z","iopub.status.busy":"2024-04-14T09:50:16.587445Z","iopub.status.idle":"2024-04-14T09:50:17.238592Z","shell.execute_reply":"2024-04-14T09:50:17.237680Z","shell.execute_reply.started":"2024-04-14T09:50:16.588090Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# Load the trained model and tokenizer\n","model_path = \"/kaggle/working/model\"  # Update with the path where your model is saved\n","tokenizer = T5Tokenizer.from_pretrained(model_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","# Define a function to generate answers for questions\n","def generate_answer(question):\n","    # Prepare input for the model\n","    input_text = f\"question: {question}\"\n","    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","    # Generate answer\n","    with torch.no_grad():\n","        output_ids = model.generate(input_ids)\n","    \n","    # Decode and return the answer\n","    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","    return answer\n","\n","# Example usage\n","question = \"What is Alzheimer's disease?\"\n","answer = generate_answer(question)\n","print(\"Answer:\", answer)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8231789,"datasetId":4670170,"sourceId":8113172,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
